{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5b23a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score)\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73729b86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"/workspaces/email-classifier-xgboost/data/spam_processed.csv\")\n",
    "X = df[\"Content\"]\n",
    "y = df[\"Label\"].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe185fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. COMPUTE OPTIMAL max_features (TF-IDF vocabulary)\n",
    "\n",
    "print(\"\\nCOMPUTING optimal max_features\")\n",
    "max_features_range = [1000, 3000, 5000, 7000, 10000]\n",
    "train_scores1, test_scores1 = validation_curve(\n",
    "    Pipeline([(\"tfidf\", TfidfVectorizer()), (\"xgb\", XGBClassifier(n_estimators=100))]),\n",
    "    X_train, y_train,\n",
    "    param_name=\"tfidf__max_features\",\n",
    "    param_range=max_features_range,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507585b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot TF-IDF learning curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(max_features_range, test_scores1.mean(axis=1), 'o-', label=\"Test Accuracy\")\n",
    "plt.axvline(np.argmax(test_scores1.mean(axis=1)), color='r', linestyle='--', label=\"Optimal\")\n",
    "optimal_features = max_features_range[np.argmax(test_scores1.mean(axis=1))]\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"TF-IDF: Optimal Vocabulary Size\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "print(f\"Optimal max_features = {optimal_features}\")\n",
    "print(f\"Test accuracies: {[f'{s:.3f}' for s in test_scores1.mean(axis=1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d15fa2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. COMPUTE OPTIMAL n_estimators (XGBoost trees)\n",
    "# =====================================================\n",
    "print(\"\\nCOMPUTING optimal n_estimators...\")\n",
    "n_estimators_range = [50, 100, 200, 300, 500]\n",
    "train_scores2, test_scores2 = validation_curve(\n",
    "    Pipeline([(\"tfidf\", TfidfVectorizer(max_features=optimal_features)), \n",
    "              (\"xgb\", XGBClassifier())]),\n",
    "    X_train, y_train,\n",
    "    param_name=\"xgb__n_estimators\",\n",
    "    param_range=n_estimators_range,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(n_estimators_range, test_scores2.mean(axis=1), 'o-', label=\"Test Accuracy\")\n",
    "plt.axvline(np.argmax(test_scores2.mean(axis=1)), color='r', linestyle='--', label=\"Optimal\")\n",
    "optimal_estimators = n_estimators_range[np.argmax(test_scores2.mean(axis=1))]\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"XGBoost: Optimal Number of Trees\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "print(f\"Optimal n_estimators = {optimal_estimators}\")\n",
    "print(f\"Test accuracies: {[f'{s:.3f}' for s in test_scores2.mean(axis=1)]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/workspaces/email-classifier-xgboost/models/optimization_curves.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccc496",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. TRAIN FINAL MODEL with COMPUTED optimal values\n",
    "# =====================================================\n",
    "print(f\"\\nTRAINING FINAL MODEL with optimal parameters:\")\n",
    "print(f\"max_features={optimal_features}, n_estimators={optimal_estimators}\")\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=optimal_features)),\n",
    "    (\"xgb\", XGBClassifier(n_estimators=optimal_estimators, random_state=40))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "print(f\"ACCURACY:        {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"PRECISION:       {precision_score(y_test, y_pred):.3f}\")\n",
    "print(f\"RECALL:          {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1-SCORE:        {f1_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "joblib.dump(final_pipeline, \"/workspaces/email-classifier-xgboost/models/spam_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
